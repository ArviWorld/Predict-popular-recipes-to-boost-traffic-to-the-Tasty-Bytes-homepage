---
title: "Predicting Recipe for Taste Bytes Homepage"
subtitle: "Building classification models to predict the recipe for enhancing website traffic"
dataset_by: "Dataset provided by Datacamp"
author: "Aravindh Venkatraman"
date: "21 September 2025"
output:
  html_document:
    toc: true
    toc_float: true
    number_sections: true
    toc_depth: 3
    df_print: tibble
    code_folding: show
    theme: default
editor_options:
  markdown:
    wrap: 72
---

# Table of Contents {.unnumbered}

[Statements](#statements)\
[Executive Summary](#executive-summary)

1.  [Introduction](#introduction)
2.  [Aim and Methodology of this
    Project](#aim-and-methodology-of-this-project)
3.  [Exploratory Data Analysis - EDA](#exploratory-data-analysis-EDA)
4.  [Machine Learning Model](#machine-learning-model)
5.  [Machine Learning Model - After Feature
    Engineering](#machine-learning-model-after-feature-engineering)
6.  [Results & Discussion](#results-&-discussions)
7.  [Conclusion, Recommendations & Next Steps](#conclusion)

# Statements {#statements .unnumbered}

**Acknowledgement**\
I sincerely thank my parents and family for their unwavering support and
encouragement, which enabled me to dedicate my time and effort to
learning Machine Learning and Artificial Intelligence and applying them
to environmental management challenges. I thank the Google Career
Certification and Datacamp Certification courses for providing me the
comprehensive resources and guidance to enhance my skills in Python, R
Programming, and Machine Learning Concepts.

**Use of generative artificial intelligence**\
Generative Artificial Iintelligence (GenAI) tools were primarily used to
assist in creating visualization, refining charts, and adjusting
plotting parameters. In addition, GenAI was used for helping me write,
debug code and improve workflow efficiency. All outputs generated by
GenAI were carefully reviewed, modified and evaluated before
implementation to ensure scientific accuracy, reliability, and alignment
with the research objectives.

**Ethical Consideration and Transparency**\
This research was conducted with transparency, rigor, and ethical
responsibility. All computational methods and analyses were
independently validated, and any use of automated or AI-assisted tools
was fully disclosed. The methodologies and code are provided to ensure
reproducibility and facilitate future research.

**Data and Code Availability**\
Where applicable, datasets, code scripts, and analysis workflows used in
this research are openly available upon request or in public
repositories, supporting transparency and reproducibility in
computational environmental management research.

# Executive Summary {#executive-summary .unnumbered}

**Problem Statement**\
Recipe displays on the Tasty Bytes homepage are chosen subjectively,
leading to inconsistent customer engagement and low traffic to the
website. When a popular recipe is displayed, overall site traffic
increases by up to 40%, assuming that it drives more subscriptions.
However, the team lacks a systematic way to predict which recipes will
generate high traffic.

**Project Aim and Focus**\
The aim of the project is to develop a data-driven prediction systems
that identifies which recipes will lead to high homepage traffic. The
focus is on achieving at least 80% accuracy in correctly predicting
high-traffic recipes, thereby suppoting subscription growth and
improving user engagement.

**Raw data used**\
The project uses a dataset (`recipe_site_traffic_2212.csv`) which
includes variables such as, recipe, nutrient contributions and servings
for the recipe, recipe category, website traffic for the recipe.

**Methodology**\
The project applies classification machine learning models to predict
popular recipes for increasing customer engagement and thereby
subscriptions. Key steps include:

-   Data Exploration and Preprocessing
-   Feature Analysis and Selection
-   Model Selection, Development and Training
-   Model Evaluation and Training
-   Deployment
-   Iteration & Monitoring

This project demonstrates how data-driven approaches can provide
actionable insights to Tasty Bytes, enabling smarter recipe selection
and promoting customer engagement and subscriptions.

**Results**\

**Key recommendations**\

# Introduction {#introduction}

The success of Tasty Bytes, a food platform, depends strongly on
engaging visitors with recipes that capture their attention. Homepage
recipes are the first point of contact for users, influencing customer
engagement and subscription. Currently, recipe selection for the
homepage is based on personal preference rather than systematic
analysis, resulting in inconsistent traffic performance.

Internal observations show that if a popular recipe is displayed,
overall website traffic can increase by up to 40%, directly contributing
to subscription growth. However, without a reliable way to predict which
recipes will be popular, the company risks missing valuable
opportunities to maximize engagement and revenue.

By analyzing recipe attributes such as nutrient composition, category,
and servings, alongside traffic outcomes, it becomes possible to predict
recipe popularity systematically. Leveraging machine learning allows a
shift from intuition-driven decisions to data-driven strategies,
improving homepage performance, driving consistent growth, and enhancing
user experience.

# Aim and Methodology of this Project {#aim-and-methodology-of-this-project}

**Aim and Focus**\
The primary objective of this project is to predict which recipes will
lead to high traffic when featured on the homepage. Specifically, the
goal is to build a classification model that can identify
high-performing recipes with at least 80% accuracy, ensuring homepage
selections consistently optimize engagement.

Focus areas include:

-   Identifying recipe attributes (nutritional values, category,
    servings) most strongly correlated with high traffic.
-   Comparing model performance using individual features vs. combined
    features.
-   Providing actionable insights to help editors select recipes
    strategically.
-   Demonstrating the role of machine learning in improving digital
    engagement and subscription growth.

This dual focus — technical model accuracy and practical business impact
— ensures the outcomes are valuable both operationally and
strategically.

**Methodology**\
The project applies binary classification models to predict traffic
outcomes (High vs. Low). The key steps include:

**Data Exploration and Preprocessing**

-   Inspect distributions of variables in the dataset.
-   Handle missing values systematically.
-   Detect and address anomalies such as negative or extreme nutrient
    values.
-   Encode categorical variables for model compatibility.

**Feature Analysis and Selection**

-   Analyze correlation between nutrient composition and traffic
    outcomes.
-   Assess the predictive power of individual features.
-   Explore category-specific performance patterns.

**Model Selection, Development, and Training**

-   Implement classification algorithms including Logistic Regression,
    Decision Trees, Random Forest, and Gradient Boosted Trees (XGBoost).
-   Train models with cross-validation to avoid overfitting.
-   Experiment with balancing strategies (since traffic labels may be
    imbalanced).

**Model Evaluation**

-   Use metrics such as Accuracy, Precision, Recall, F1-score, and
    ROC-AUC.
-   Compare model performances to identify the best approach.
-   Ensure models consistently achieve ≥80% accuracy in predicting High
    traffic.

**Feature Importance Extraction**

-   Use ensemble models (Random Forest, XGBoost) to determine which
    features drive traffic predictions.
-   Cross-validate with simpler models to confirm robustness.

The outcome will demonstrate how data-driven recipe selection supports
homepage editors in making informed choices, driving traffic growth, and
ultimately increasing subscriptions.

# Exploratory Data Analysis - EDA {#exploratory-data-analysis-EDA}

First, load the necessary libraries in R that are essential for the
success of the **“Recipe Popularity Prediction”** project. These include
packages for data handling, analysis, processing, visualization, machine
learning, and model evaluation.

```{r loading libraries, message = FALSE, warning = FALSE}

# Operational libraries
library(tidyverse)    # Data manipulation and visualization
library(dplyr)        # Data manipulation

# Visualization
library(ggplot2)      # Powerful and flexible plotting
library(GGally)       # Pair plot
library(ggfortify)
library(RColorBrewer)
library(viridis)
library(naniar)       # Visualize missing values
library(kableExtra)   # Table styling
library(corrplot)     # Correlation plots
library(gridExtra)    # Arranging multiple plots
library(patchwork)    # Arranging multiple plots
library(Rtsne)
library(Ckmeans.1d.dp)  # required
library(DiagrammeR)

# Modelling
library(caret)        # Splitting dataset and model evaluation
library(glmnet)       # Regularized logistic regression
library(rpart)        # Decision tree
library(rpart.plot)   # Plot the decision tree
library(randomForest) # Random Forest Model
library(xgboost)      # Gradient boosting Model

# Model metrics and evaluation 
library(ModelMetrics) # ML Model metrics
library(pROC)         # ROC curves and AUC metrics
library(DALEX)        # Model interpretability

```

## Data Loading and Pre-processing

### Data exploration

The first step of the project involves exploring the distribution of
features in the dataset `recipe_site_traffic_2212.csv`.

```{r data loading}

path <- "D:/Study/Machine Learning/Projects/Completed projects for GitHub/Predict-popular-recipes-to-boost-traffic-to-the-Tasty-Bytes-homepage/Raw Data/recipe_site_traffic_2212.csv"

# load the dataset
recipe_df <- read.csv(path)

kable(head(recipe_df), caption = "Soil Measurements") %>%
  kable_styling(full_width = F, position = "left")

# Structure of the dataset
str(recipe_df)

```

**Dataset Description**

Each row represents a recipe instance described by:

-   Recipe ID (`recipe`) – unique identifier.
-   Nutrient Composition:
    -   `calories`: energy content per recipe.
    -   `carbohydrate`: carbohydrate content.
    -   `sugar`: sugar content.
    -   `protein`: protein content.
-   Category (`category`) – recipe type (e.g., Beverages, Lunch/Snacks,
    Pork).
-   Servings (`servings`) – number of servings per recipe.
-   Traffic (`traffic`) – target variable, categorical.

**Analysis steps include:**

-   Aligning the variable data types and names for analysis purpose and
    better readability.
-   Examining central tendencies, ranges, and variability for each
    nutrient.
-   Identifying and handling missing values in nutrients, servings, and
    traffic.
-   Checking for anomalies such as outliers, negative or implausible
    values.
-   Preparing the dataset (scaling nutrients, encoding categorical
    variables) for predictive modeling.

This analysis provides a structured foundation for building reliable
models that predict which recipes are most likely to succeed on the
homepage.

### Data Analysis

**1. Examining variable datatypes and distributions**

-   *Aligning the data types for consistent analysis and renaming the
    column names for better readability.*
-   Computed summary statistics (mean, median, min, max, variance) for
    nutrient composition - `calories`, `carbohydrate`, `sugar`, and
    `protein`.

```{r data exploration, warning = FALSE, message = FALSE}

# Changing the datatypes for efficient analysis
recipe_df$servings = as.integer(recipe_df$servings)

# Realigning the variable names for easy use and readability
recipe_df <- recipe_df %>%
  select(recipe, category, servings, calories, 
         carbohydrate, sugar, protein, traffic = high_traffic)

# Statistical Summary of the dataset
kable(summary(recipe_df), caption = "Descriptive Statistics of Recipe Dataset") %>%
  kable_styling(full_width = F, position = "left")

```

-   The dataset `recipe_site_traffic_2212.csv` consists of 947
    observations and 8 variables.

-   Columns such as recipe (ID) and servings were aligned to proper data
    types (numeric for computation, categorical for grouping). Column
    names were cleaned for clarity and consistency.

-   Nutrient composition variables (calories, carbohydrate, sugar,
    protein) were analyzed for central tendency and spread.

    -   Calories ranged from very low values (\<50 kcal) in beverages to
        \>900 kcal in heavy dishes like pork-based recipes.
    -   Carbohydrates and sugar showed large variability, with high
        values concentrated in desserts and beverages.
    -   Protein was strongly skewed, with higher levels in meat-based
        categories.

-   Variability confirmed that the dataset captures a broad spectrum of
    recipe types, with distinct nutritional profiles across categories.

**2. Handling duplicate and missing values**

Identifying duplicate and missing values is crucial to get a better and
consistent data for modelling.

```{r missing values summary, warning = FALSE, message = FALSE}

# Check for duplicate values
duplicate_values <- sum(duplicated(recipe_df))

kable(duplicate_values, caption = "Duplicated values in the Dataset") %>%
  kable_styling(full_width = F, position = "left")

# Visualizing the missing values
recipe_miss <- recipe_df %>%
  select(where(~ any(is.na(.))))

miss_h_p1 <- vis_miss(recipe_miss, cluster = TRUE, sort_miss = TRUE) +
  ggtitle("Heatmap of Missing values by similarity")
miss_h_p2 <- gg_miss_var(recipe_miss) +
  ggtitle("Missing values by Variable")

# Plotting
miss_h_p1 + miss_h_p2

# Missing data summary grouped by category
nutrient_vars <- c("calories", "carbohydrate", "sugar", "protein")

missing_summary <- recipe_df %>%
  summarize(
    frequency = as.integer(n()),
    rows_with_any_na = sum((if_any(everything(), is.na))),
    rows_ht_na = sum(is.na(traffic)),
    rows_nutrient_na = sum(if_all(all_of(nutrient_vars), is.na)),
    rows_ht_ser = sum(is.na(servings))
  ) 

kable(missing_summary, caption = "Distribution of Missing values - Recipe Dataset") %>%
  kable_styling(full_width = F, position = "left")

```

-   **Duplicates:** No duplicate rows were identified in the dataset,
    confirming unique recipe records.
-   **Overall missing values:** Approximately 10.3% of the dataset
    contains missing values.
    -   Missing values are not randomly distributed — they are clustered
        across specific variables and observations.
-   **Variable-level missing values:**
    -   **Target Variable (`traffic`)** has 373 missing values. Only
        "High" values are explicitly recorded in the dataset, while
        missing values indicate that recipes did not drive high traffic.
        Thus, imputing missing values as "Low" is justified.
    -   Nutrient composition (`calories`, `carbohydrate`, `sugar`,
        `protein`) has 52 missing observations, and importantly, these
        values are missing together within the same rows, across
        categories.
    -   `Servings` has 3 missing values, all in the “Lunch/Snacks”
        category.
-   **Pattern of missing values:**
    -   414 rows (43.7% of the dataset) contain at least one missing
        value.
    -   13 rows are missing both traffic and nutrient composition.
    -   No missing values are present in the recipe ID or category.

**Imputation strategy applied**

-   ***Traffic (`traffic`):*** Since only `"High"` outcomes were
    explicitly logged, missing values were systematically imputed as
    `"Low"`. This assumption aligns with the data collection process and
    business context, ensuring the target variable fully represents both
    classes for classification.

-   ***Nutrients (`calories`, `carbohydrate`, `sugar`, `protein`):***
    Missing nutrient values were imputed using category-level
    per-serving averages. Nutrient-per-serving values were first
    computed, and missing totals were estimated by multiplying these
    averages by the known servings. This method preserves the
    proportional relationship between nutrients and servings and ensures
    imputed values remain realistic for each recipe category.

-   ***Servings (`servings`):*** Three missing values, all within the
    `Lunch/Snacks` category, were imputed using nutrient-per-serving
    ratios. Servings were estimated by dividing the recipe’s nutrient
    values by the mean per-serving nutrient values for the category.
    When multiple nutrients were available, estimates were
    cross-validated for consistency, minimizing bias.

```{r missing imputation, warning  = FALSE, message = FALSE}

# Generate the corresponding per_serving column names
nutrient_vars_per_serving <- paste0(nutrient_vars, "_per_serving")

# Calculating the nutrient composition per serving for all observations
recipe_df <- recipe_df %>%
  group_by(category) %>%
  mutate(across(all_of(nutrient_vars), 
                ~ .x / servings, 
                .names = "{.col}_per_serving")) %>%
  mutate(round(across(all_of(nutrient_vars_per_serving),
                ~ ifelse(is.na(.x), mean(.x, na.rm = TRUE), .x)), 2)) %>%
  ungroup()

# Imputing all the high_traffic NAs with `Low`
recipe_clean <- recipe_df %>%
  mutate(traffic = factor(
    if_else(is.na(traffic), "Low", traffic),
    levels = c("Low", "High")))

# Imputing the missing values in the servings and nutrient composition of the category
# Imputing the missing serving values in Lunch/Snack Category
recipe_clean <- recipe_clean %>%
  rowwise() %>%
  mutate(
    servings = ifelse(
      is.na(servings),
      round(mean(c_across(all_of(nutrient_vars)) /
                   c_across(all_of(nutrient_vars_per_serving)), 0)), servings)) %>%
  ungroup()

# Imputing the missing nutrient composition values 
recipe_clean <- recipe_clean %>%
  rowwise() %>%
  mutate(across(
    all_of(nutrient_vars),
    ~ ifelse(is.na(.x),
             c_across(all_of(paste0(cur_column(), "_per_serving"))) * servings, .x))) %>%
  ungroup()

recipe_clean <- recipe_clean %>%
  select(-ends_with("_per_serving")) %>%
  select(-recipe) %>%
  mutate(traffic = as.factor(traffic))

kable(head(recipe_clean), caption = "Cleaned Recipe dataset") %>%
  kable_styling(full_width = F, position = "left")

```

**Assessment:** This imputation strategy supports the project’s goals by
ensuring a complete, consistent dataset without distorting the
underlying nutritional logic. By grounding imputations in serving
proportions and category-level norms, the approach retains realistic
recipe variability, enabling reliable modeling of traffic outcomes.

**Checking anomalies**

-   Identifying and validating anomalies, implausible and outlier values
    in the cleaned dataset.

```{r cleaned data summary, warning = FALSE, message = FALSE}

kable(summary(recipe_clean), caption = "Descriptive Statistics of Cleaned Recipe Dataset") %>%
  kable_styling(full_width = F, position = "left")

```

-   **RecipeID:** RecipeID represents the continuous unique identifier
    for each recipe and is dropped from the cleaned dataset.
-   ***Servings:*** Values range between 1 and 6, which is plausible and
    consistent with typical recipe sizes. No negative or implausible
    serving values were observed after cleaning.
-   ***Calories:*** Ranges from 0.14 kcal (likely a very light beverage
    or recording error) up to 3633 kcal (likely a multi-serving dense
    dish). The upper tail represents genuine high-calorie recipes, but
    these values are consistent with rich or multi-ingredient meals.
-   ***Carbohydrates:*** Range from 0.03 g to 530.42 g. The maximum
    reflects carbohydrate-heavy dishes (e.g., pasta or desserts). No
    negative values were found.
-   ***Sugar:*** Range from 0.01 g to 148.75 g. The higher end
    corresponds to desserts and beverages, which aligns with
    expectations.
-   ***Protein:*** Range from 0.00 g to 363.36 g. The maximum reflects
    meat- or protein-rich recipes. A few 0 g protein values were
    flagged, corresponding to beverages or low-protein dishes, and are
    not implausible.
-   ***Traffic (Target Variable):*** Distribution is 574 `High` (60%)
    vs. 373 `Low` (40%), indicating a moderate class imbalance but no
    anomalies.

**Insight:** Nutrient ranges are consistent with expectations of food
categories (e.g., pork and meat dishes being protein-dense, desserts
being sugar-dense). This variability is important for distinguishing
recipe types and traffic outcomes in modeling.

**EDA Outcomes and Insights - Summary**

-   The recipe dataset is well-structured with a clear distinction
    between predictors (nutrients, category, servings) and outcome
    (traffic).
-   Missing data was systematic and imputations ensured proportionality
    between nutrients and servings while respecting category norms.
-   Nutrient ranges align with expected category patterns (e.g.,
    desserts sugar-dense, meat dishes protein-rich). Outliers reflect
    natural variation across recipe types and add useful variance, not
    noise.
-   Outliers are informative, not errors, and should be preserved for
    modeling as they contribute to recipe diversity.
-   Nutrient profiles by category provide meaningful differentiation
    aligned with real-world recipe expectations.
-   The target variable (`traffic`) shows a slight imbalance (60% High
    and 40% Low), but not extreme, making it suitable for standard
    classification approaches.

The dataset is now ready for visualization and modelling, with variables
prepared, anomalies understood, and imputations aligned with business
and nutritional logic. This ensures predictive models will have both
statistical rigor and real-world interpretability.

### Data Visualization

Data visualization was carried out to explore the distribution of recipe
features, identify patterns across categories and servings, and uncover
relationships between nutrients and traffic. These visualizations
provide both statistical and business insights, helping guide feature
engineering and model building.

#### **Distribution of Recipe Variables**

Visualizing the spread of nutrients composition (calories, carbohydrate,
sugar, protein) helps in understanding the central tendencies, skewness,
and presence of outliers. This step highlights the diversity across
recipes and informs whether feature scaling or transformation is
required before modeling.

**Histograms / Density Plots**

-   Histograms and density plots were created for each nutrient variable
    to examine their distributions.
-   These plots reveal whether nutrient values are normally distributed
    or skewed, and highlight categories of recipes with extreme nutrient
    values.
-   Identifying these patterns is useful in detecting the need for
    normalization and ensuring balanced model performance.

```{r recipe distribution, warning = FALSE, message = FALSE}

# Histogram and Density plots for nutrient composition
histogram <- recipe_clean %>%
  gather(key = "nutrients", value = "value", nutrient_vars) %>%
  ggplot(aes(x = value, fill = nutrients)) +
  geom_histogram(aes(y = ..density..), binwidth = 0.3, alpha = 0.8) +
  geom_density(alpha = 0.8) +
  scale_x_log10() +
  facet_wrap(~ nutrients, scales = "free") +
  scale_fill_brewer(palette = "Dark2") +
  labs(title = "Distribution of Nutrient composition",
     x = "Value",
     y = "Count") +
  theme_minimal()
 
histogram

```

**Insights**

Histogram distribution shows right skewed tailed, which means that there
are lot of higher values. Hence, log scale transformation is required
and shows almost normal distribution for all nutrient composition. It
seems like there are outliers in each nutrient components but each
outlier is representable for the analysis as each recipe has its own
nutrient composition.

#### **Traffic Insights**

Visualizations reveal how recipe categories influence homepage traffic.
Vegetable recipes attract the highest proportion of high traffic, while
beverages are more associated with low traffic. These patterns provide
an initial understanding of user preferences before diving into
model-based feature importance.

**Bar Plot / Count Plot**

A bar plot was used to show the distribution of the target variable
(traffic) across recipe categories. This highlights which categories
most frequently drive high traffic. A similar plot was generated for
servings, showing whether portion size plays a role in traffic outcomes.

```{r traffic1, warning = FALSE, message = FALSE}

# Bar plot for traffic across different categories 
bar_traffic_cat <- recipe_clean %>%
  ggplot(aes(x = category, fill = traffic)) +
  geom_bar(position = "dodge", alpha = 0.8) +
  scale_fill_brewer(palette = "Dark2") +
  labs(title = "Bar plot for traffic across different categories", 
       x = "Value",
       y = "Count") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 0.5, size = 10))

bar_traffic_cat

# Bar plot for traffic across different servings
bar_traffic_ser <- recipe_clean %>%
  ggplot(aes(x = servings, fill = traffic)) +
  geom_bar(position = "dodge", alpha = 0.8) +
  scale_fill_brewer(palette = "Dark2") +
  labs(title = "Bar plot for traffic across different servings", 
       x = "Value",
       y = "Count") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 0.5, size = 10))

bar_traffic_ser

```

**Insights**

-   Vegetable, Potato & Pork are the top three recipe category having
    highest count of high traffic when displayed on the webpage
-   Beverages, Breakfast & Chicken Breast have the high counts of Low
    traffic among the recipe category.
-   All the servings have a more high traffic than the low, 4 & 6
    serving dishes have scored more. 3 serving is cause of the
    imputation strategy to fill in the missing value.

#### **Histogram of Traffic vs. Nutrient Composition**

Histograms of nutrients split by traffic levels were generated. These
plots help reveal whether nutrient intensity (e.g., high-calorie or
high-protein recipes) correlates with higher traffic.

```{r traffic2, warning = FALSE, message = FALSE}

# Histogram plot of traffic across nutrient composition
bar_nutrient <- recipe_clean %>%
  gather(key = "nutrients", value = "value", nutrient_vars) %>%
  ggplot(aes(x = value, fill = traffic)) +
  geom_histogram(position = "dodge", binwidth = 0.3, alpha = 0.8) +
  scale_x_log10() +
  facet_wrap(~ nutrients, scales = "free") +
  scale_fill_brewer(palette = "Dark2") +
  labs(title = "Distribution of Nutrient composition",
     x = "Value",
     y = "Count") +
  theme_minimal()
 
bar_nutrient

```

**Insights**

-   All the nutrients as highly right skewed same as the histogram
    before and is log transformed, but differentiated bu the high and
    low traffic in this graph.

-   High traffic is more than the low traffic in all of the nutrient
    composition.

**Heatmap of Traffic by Category and Servings**

A two-dimensional heatmap was created to show how recipe categories and
serving sizes jointly influence traffic outcomes. This allows us to
visually capture interactions, such as whether larger servings in
certain categories are more likely to attract high traffic.

```{r traffic3, warning = FALSE, message = FALSE}

# Heatmap of Traffic by Category and Servings
heatmap_data <- recipe_clean %>%
  group_by(category, servings, traffic) %>%
  summarise(count = n(), .groups = "drop")

hm_traffic_ser <- ggplot(heatmap_data, aes(x = as.factor(servings), y = category, fill = count)) +
  geom_tile(color = "white", alpha = 0.8) +
  facet_wrap(~traffic) +
  scale_fill_gradient(low = "#1b9e77", high = "#d95f02") +
  labs(title = "Heatmap of Traffic by Category and Servings",
       x = "Servings", y = "Category", fill = "Count") +
  theme_minimal()

hm_traffic_ser

```

**Insights**

-   4 servings scored the most in both High and low traffic,
-   Vegetable, Potatoes and Pork have scored high traffic mainly in the
    4 servings recipe
-   Breakfast, Beverages and chicken breast have scored high in the low
    traffic in the 4 servings recipe.

#### **Feature Relationships**

Exploratory plots highlight how nutritional attributes (calories,
carbohydrate, sugar, protein) and servings vary across categories and
traffic outcomes. These relationships help identify potential drivers of
visibility, supporting model selection and interpretation of variable
importance.

**Correlation Heatmap**

-   A correlation heatmap was generated for the nutrient variables.
-   This visualization helps identify multicollinearity (e.g., strong
    correlation between calories and carbohydrates) and provides insight
    into which features contribute unique information for
    classification.
-   Understanding correlations supports feature selection and reduces
    redundancy in the predictive model.

```{r feature relationhship, warning = FALSE, message = FALSE}

# Correlation Matrix for the soil parameters
cor_matrix <- cor(recipe_clean %>% select(c(nutrient_vars, servings)))
corrplot(cor_matrix, method = "circle", type = "upper",
         tl.col = "black", tl.srt = 45, 
         col = adjustcolor(colorRampPalette(c("#1b9e77", "#d95f02"))(200), 
                           alpha.f = 0.8),
         addCoef.col = "black", number.cex = 0.7, number.digits = 2,
         title = "Correlation Matrix of nutrient composition",
         insig = "blank", tl.cex = 0.8, cl.cex = 0.8, 
         cl.lim = c(-1, 1), mar = c(0,0,1,0))

```

**Insights**

Correlation plot indicates that there are no direct realationship within
the numeric variables in the cleaned dataset.

# Machine Learning Models

The exploratory data analysis (EDA) indicated that nutrient composition,
category, and serving size all influence recipe traffic. To leverage
these insights, several classification models were developed and
evaluated to predict whether a recipe will generate High or Low traffic.

**Model Selection**\
To assess predictive performance, we applied both linear and non-linear
models:

-   **Logistic Regression:** *Baseline model* to assess linear
    relationships between recipe features and traffic.
-   **Decision Trees:** To capture non-linear relationships and feature
    interactions.
-   **Random Forest:** An ensemble approach to improve accuracy and
    identify important predictors.
-   **Gradient Boosted Trees (XGBoost):** For advanced boosting-based
    classification, focusing on minimizing misclassifications.

These models allow us to compare simple vs. complex algorithms and
balance interpretability with predictive accuracy.

**Data Split and Model Training**\
The dataset was split into training (70%) and testing (30%) sets to
evaluate generalizability. Cross-validation was applied on the training
set to ensure robust performance estimates. Hyperparameter tuning was
carried out using grid search/random search to optimize model
performance for Random Forest and XGBoost.

**Data preparation for modelling**

-   Continuous features (`calories`, `carbohydrate`, `sugar`, `protein`,
    `servings`) were normalized and scaled to ensure comparability
    across different ranges.
-   The categorical variable category was one-hot encoded to convert it
    into a machine-readable form.
-   The target variable traffic was converted into a binary factor:
    `Low` = 0, `High` = 1; and indicates 60% `High` and 40% `Low` class
    imbalance within the cleaned dataset, which is acceptable for the
    models selected.

The final cleaned dataset was prepared accordingly to support machine
learning workflows.

```{r data split}

# Set seed for reproducibility
set.seed(123)

str(recipe_clean)

# Split into training and test datasets
train_index <- createDataPartition(recipe_clean$traffic, p = 0.7, list = FALSE)
train <- recipe_clean[train_index, ]
test <- recipe_clean[-train_index, ]

# Dummy encoding for categorical variables
dummies <- dummyVars(traffic ~., data = train)

train_dummy <- predict(dummies, newdata = train)
test_dummy <- predict(dummies, newdata = test)

# Add back target column
train_proc <- data.frame(train_dummy, traffic = train$traffic)
test_proc <- data.frame(test_dummy, traffic = test$traffic)

# PreProcessing the recipe_clean dataset for normalization across models
preProc <- preProcess(train, method = c('center', 'scale'))

train_final <- predict(preProc, train_proc)
test_final <- predict(preProc, test_proc)

# True labels
true_labels <- test_final$traffic

```

# Machine Learning Model {#machine-learning-model}

The machine learning models are built using the training dataset, and
their performance is evaluated on the testing dataset. The models are
trained using the soil parameters (N, P, K, pH) as features to predict
the crop type.

**Functions for Model Metric and Evaluation**

To ensure consistent evaluation, reusable functions were developed for:

-   **Confusion Matrix:** To summarize correct vs. incorrect predictions
    across Low/High traffic.
-   

```{r model eval cm, warning = FALSE, message = TRUE}

# Functions to plot confusion matrix
plot_cm <- function(cm, model_name) {
    cm_df <- as.data.frame(cm$table)
    colnames(cm_df) <- c("Prediction", "Reference", "Frequency")
    cm_df$Model <- model_name
    return(cm_df)
}

```

-   **Model Metrics Dataframe:** A consolidated table of performance
    metrics (Accuracy, Precision, Recall, F1-score, ROC-AUC) for each
    model, enabling easy comparison.

```{r model eval metrics, warning = FALSE, message = TRUE}

# Function to get metrics for the model
get_metrics <- function(cm, auc_val, model_name = "Model"){
  accuracy <- as.numeric(cm$overall["Accuracy"])
  sensitivity <- as.numeric(cm$byClass["Sensitivity"])
  specificity <- as.numeric(cm$byClass["Specificity"])
  precision <- as.numeric(cm$byClass["Pos Pred Value"])
  if(!is.na(precision) & !is.na(sensitivity)){
    f1 <- 2 * ((precision * sensitivity) / (precision + sensitivity))
  } else {
    f1 <- NA
  }
  # Return as a dataframe
  df <- data.frame(
    Model = model_name,
    Accuracy = accuracy,
    Precision = precision,
    Recall = sensitivity,
    Specificity = specificity,
    F1_score = f1,
    ROC_AUC = as.numeric(auc_val))
  
  return(df)
}

```

-   **Variable Importance plots:**

```{r model eval varimp, warning = FALSE, message = TRUE}
# Function to plot variabe importance for models
plot_all_varimp <- function(models, model_names) {
  
  varimps <- lapply(seq_along(models), function(i) {
    vi <- varImp(models[[i]], scale = TRUE)$importance
    vi <- vi %>%
      tibble::rownames_to_column("Variable") %>%
      mutate(Model = model_names[i])
    # Handle binary classification outputs (Low/High)
    if ("Low" %in% colnames(vi) & "High" %in% colnames(vi)) {
      vi <- vi %>%
        mutate(Importance = pmax(Low, High)) %>%
        select(Variable, Importance, Model)
    } else {
      vi <- vi %>%
        rename(Importance = Overall) %>%
        select(Variable, Importance, Model)
    }
    # Scale within model to [0,100]
    vi <- vi %>%
      mutate(Importance = 100 * Importance / max(Importance, na.rm = TRUE))
    return(vi)
  })
  varimp_df <- bind_rows(varimps)
}

```

-   **ROC-AUC Plots:** To visualize trade-offs between sensitivity and
    specificity and compute the area under the curve (AUC).

```{r model eval ROC-AUC, warning = FALSE, message = TRUE}

# Function to plot ROC with AUC and highlighted threshold point
roc_to_df <- function(roc_obj, model_name = "Model") {
  # Full ROC curve
  roc_df <- data.frame(
    FPR = 1 - roc_obj$specificities,
    TPR = roc_obj$sensitivities,
    Model = model_name)
  # Best threshold using Youden's index
  opt <- coords(roc_obj, "best", 
    ret = c("specificity", "sensitivity"), 
    best.method = "youden")
  opt <- as.numeric(opt)  # ensure numeric
  # Threshold point dataframe with correct column names
  point_df <- data.frame(
    FPR = 1 - opt[1],  # 1 - specificity
    TPR = opt[2],      # sensitivity
    Model = model_name)
  # Compute AUC
  auc_val <- as.numeric(auc(roc_obj))
  # Add auc_val column to roc_df
  roc_df$AUC <- auc_val
  point_df$AUC <- auc_val
  # Return all
  return(list(
    roc_df = roc_df,
    point_df = point_df,
    auc = auc_val
  ))
}

```

In this session, we train the models, prepare the variables for model
results, generate the particular model metric and visualize the plot
trees. All these function will be presented at next section - model
results and evaluation where it will be discussed on the model
performance.

## Logistic Regression

Logistic Regression was used as the baseline classifier. It models the
probability of a recipe driving high traffic as a function of nutrient
composition, servings, and category. Coefficients provide interpretable
insights into which recipe attributes positively or negatively influence
high traffic. Performance metrics and ROC curves were generated to
benchmark against more complex models.

```{r logistic regression, message = FALSE, warning = FALSE}

# Building the logistic regression model
log_model <- train(traffic ~ . + 0, data = train_final,
                   method = 'glmnet', family = "binomial",
                   trControl = trainControl(method = 'cv',
                              number = 5))

# Extract coefficients and odds ratios
log_coef <- broom::tidy(log_model$finalModel) %>%
  mutate(OddsRatio = exp(estimate)) %>%
  filter(term != "(Intercept)")

# Plot with Dark2 colors, filled by odds ratio value
ggplot(log_coef, aes(x = reorder(term, OddsRatio),
                     y = OddsRatio,
                     fill = OddsRatio)) +
  geom_col(alpha = 0.9) +
  coord_flip() +
  scale_fill_gradient(low = "#1b9e77", high = "#d95f02") +
  theme_minimal(base_size = 12) +
  labs(title = "Logistic Regression Coefficients (Odds Ratios)",
       x = "Variable",
       y = "Odds Ratio (exp(coef))",
       fill = "Odds Ratio")

# Predict the target variable using the test data
log_preds <- predict(log_model, test_final)

# Construct the confusion matrix
log_cm <- caret::confusionMatrix(log_preds, test_final$traffic)
plot_log <- plot_cm(log_cm, "Logistic Regression")

# Logistic regression model results
log_results <- get_metrics(log_cm, roc_log$auc, "Logistic Regression")

# Print the results
kable(log_results, caption = "Logistic Regression Model Results") %>%
  kable_styling(full_width = F, position = "left")

# ROC dataframe
log_probs <- predict(log_model, test_final, type = "prob")[, "High"]
roc_log <- roc(true_labels, log_probs)
roc_log <- roc_to_df(roc_log, "Logistic Regression")

```

## Decision Tree

```{r decision tree model, message = FALSE, warning = FALSE}

# Building the logistic regression model
dt_model <- train(traffic ~ ., 
                  data = train_final,
                  method = 'rpart', 
                  trControl = trainControl(
                    method = 'cv',
                    number = 5),
                  tuneLength = 10)

# Plot the tree
rpart.plot(dt_model$finalModel, type = 3, 
           extra = 104, under = TRUE, tweak = 1.2, 
           fallen.leaves = TRUE, main = "Decision Tree")

# Predict the target variable using the test data
dt_preds <- predict(dt_model, test_final)

# Construct the confusion matrix
dt_cm <- caret::confusionMatrix(dt_preds, test_final$traffic)
plot_dt <- plot_cm(dt_cm, "Decision Tree")

# Logistic regression model results
dt_results <- get_metrics(dt_cm, roc_dt$auc, "Decision Tree")

# Print the results
kable(dt_results, caption = "Decision Tree Model Results") %>%
  kable_styling(full_width = F, position = "left")

# ROC dataframe
dt_probs <- predict(dt_model, test_final, type = "prob")[, "High"] # for ROC curve
roc_dt <- roc(true_labels, dt_probs)
roc_dt <- roc_to_df(roc_dt, "Decision Tree")

```

## Random Forest

Random Forest was implemented to capture non-linear relationships
between features and recipe traffic.

Feature importance scores were extracted to highlight which nutrients or
attributes most strongly influence traffic.

This approach improves prediction accuracy while providing
interpretability regarding key drivers of engagement.

```{r rf model, message = FALSE, warning = FALSE}

# Building the logistic regression model
rf_model <- train(traffic ~ ., data = train_final,
                  method = 'rf', 
                  trControl = trainControl(
                    method = 'cv',
                    number = 5),
                  importance = TRUE)

# Plot with full customization
tree_rpart <- rpart(traffic ~ ., data = train_final, method = "class")

rpart.plot(tree_rpart, type = 3, 
           extra = 104, fallen.leaves = TRUE,
           cex = 1, box.col = c("lightgreen", "orange"),
           border.col = "black", shadow.col = "gray",
           under = TRUE, branch.lty = 1,
           main = "Random Forest - Example Tree")

# Predict the target variable using the test data
rf_preds <- predict(rf_model, test_final)

# Construct the confusion matrix
rf_cm <- caret::confusionMatrix(rf_preds, test_final$traffic)

# Plotting the confusion matrix
plot_rf <- plot_cm(rf_cm, "Random Forest")

# Logistic regression model results
rf_results <- get_metrics(rf_cm, roc_rf$auc, "Random Forest")

# Print the results
kable(rf_results, caption = "Random Forest Model Results") %>%
  kable_styling(full_width = F, position = "left")

# ROC dataframe
rf_probs <- predict(rf_model, test_final, type = "prob")[, "High"] # for ROC curve
roc_rf <- roc(true_labels, rf_probs)
roc_rf <- roc_to_df(roc_rf, "Random Forest")

```

## XGB Boost

```{r xgb model, message = FALSE, warning = FALSE}

# Building the logistic regression model
xgb_model <- train(traffic ~ ., data = train_final, method = "xgbTree",
                   trControl = trainControl(method = "cv", number = 5),
                   tuneGrid = expand.grid(
                     nrounds = 50, max_depth = 3,
                     eta = 0.1, gamma = 0,
                     colsample_bytree = 1, min_child_weight = 1, subsample = 1)
)

# Plot the tree
xgb.plot.tree(model = xgb_model$finalModel, trees = 3,
              show_node_id = TRUE, render = TRUE)

# Predict the target variable using the test data
xgb_preds <- predict(xgb_model, test_final)

# Construct the confusion matrix
xgb_cm <- caret::confusionMatrix(xgb_preds, test_final$traffic)

# Plotting the confusion matrix
plot_xgb <- plot_cm(xgb_cm, "XGB Boost")

# Logistic regression model results
xgb_results <- get_metrics(xgb_cm, roc_xgb$auc, "XGB Boost")

# Print the results
kable(xgb_results, caption = "XGB Boost Model Results") %>%
  kable_styling(full_width = F, position = "left")

# ROC dataframe
xgb_probs <- predict(xgb_model, test_final, type = "prob")[, "High"] 
roc_xgb <- roc(true_labels, xgb_probs)
roc_xgb <- roc_to_df(roc_xgb, "XGB Boost")

```

# Model Results and Evaluation

Performance was evaluated using confusion matrix, model metrics table,
variable importance plots and ROC-AUC plots on the test dataset.

**Confusion Matrix**

-   The confusion matrix revealed class-level performance (e.g., ability
    to correctly identify high traffic vs. low traffic recipes).

```{r confusion matrix, warning = FALSE, message = FALSE}

# Combine all confusion matrices
all_cm <- bind_rows(plot_log, plot_dt, plot_rf, plot_xgb)

# Optional: convert Prediction & Reference to factors with consistent levels
levels_order <- c("Low", "High")
all_cm <- all_cm %>%
  mutate(
    Prediction = factor(Prediction, levels = levels_order),
    Reference = factor(Reference, levels = levels_order)
  ) %>%
  mutate(Label = case_when(
    Prediction == "High" & Reference == "High" ~ "True Positive (TP)",
    Prediction == "High" & Reference == "Low"  ~ "False Positive (FP)",
    Prediction == "Low"  & Reference == "Low"  ~ "True Negative (TN)",
    Prediction == "Low"  & Reference == "High" ~ "False Negative (FN)",
    TRUE ~ ""
  ))

# Plot confusion matrices with labels
ggplot(all_cm, aes(x = Reference, y = Prediction, fill = Frequency)) +
  geom_tile(color = "white") +
  geom_text(aes(label = paste0(Frequency, "\n", Label)), color = "black", size = 3) +
  scale_fill_gradient(low = "#1b9e77", high = "#d95f02") +
  theme_minimal() +
  facet_wrap(~Model, ncol = 2, scales = "fixed") +  # fixed axes
  labs(title = "Confusion Matrices Across Models", fill = "Count") +
  theme(
    plot.title = element_text(hjust = 0.5),
    axis.text.x = element_text(angle = 45, hjust = 1))

```

**Insights**

**Model Metrics Comparison**

-   Results were consolidated into a comparison table to assess which
    model best meets the project goal of ≥ 70% accuracy.

```{r model results, warning = FALSE, message = FALSE}

combined_results <- bind_rows(log_results, dt_results, rf_results, xgb_results)

model_results <- combined_results %>%
  select(-Model) %>%
  t() %>%
  as.data.frame() %>%
  rownames_to_column(var = "Metric") 

# Round only numeric columns
model_results[, -1] <- round(model_results[, -1], 3)

colnames(model_results)[-1] <- combined_results$Model

kable(model_results, caption = "Model Results") %>%
  kable_styling(full_width = F, position = "left")

```

**Insights**

**Variable Importance Plots**

-   Variable Importance shows which variables were prioritized for the
    model predictions.

```{r var imp plot, warning = FALSE, message = FALSE}

# Creating data frame to plot all the variable importance
varimp_df <- plot_all_varimp(
  models = list(log_model, rf_model, xgb_model, dt_model),
  model_names = c("Logistic Regression", "Random Forest", "XGBoost", "Decision Tree")
)

# Apply the variable importance function
ggplot(varimp_df, aes(x = reorder(Variable, Importance),
                      y = Importance,
                      fill = Model)) +
  geom_col(position = position_dodge(width = 0.9), 
           width = 0.7, alpha = 0.8) +
  coord_flip() +
  
  # Add spacing between variables
  scale_x_discrete(expand = expansion(mult = c(0.05, 0.05))) +
  
  # Color palette (color-blind safe)
  scale_fill_brewer(palette = "Dark2") +
  
  # Styling
  theme_minimal(base_size = 14) +
  theme(
    axis.text.y  = element_text(size = 10, hjust = 1),
    axis.text.x  = element_text(size = 10),
    axis.title   = element_text(size = 12, face = "bold"),
    legend.title = element_text(size = 11),
    legend.text  = element_text(size = 10),
    panel.grid.major.y = element_blank(),  # removes y gridlines between bars
    plot.title   = element_text(size = 16, face = "bold", hjust = 0.5)
  ) +
  
  labs(title = "Scaled Variable Importance Across Models",
       x = "Variable",
       y = "Scaled Importance (0–100)")

```

**Insights**

**ROC_AUC Plots**

-   ROC-AUC analysis validated the trade-offs in model sensitivity and
    specificity.

```{r ROC results, warning = FALSE. message = FALSE}

# Combine ROC curves and threshold points from multiple models
all_roc_df <- bind_rows(roc_log$roc_df, roc_dt$roc_df, roc_rf$roc_df, roc_xgb$roc_df)
all_point_df <- bind_rows(roc_log$point_df, roc_dt$point_df, roc_rf$point_df, roc_xgb$point_df)

# Add label column for unified legend
all_roc_df <- all_roc_df %>%
  mutate(Label = paste0(Model, " (AUC=", round(AUC, 3), ")"))

all_point_df <- all_point_df %>%
  left_join(all_roc_df %>% distinct(Model, Label), by = "Model")

# Plot
ggplot(all_roc_df, aes(x = FPR, y = TPR, color = Label)) +
  geom_line(size = 1) +
  geom_point(data = all_point_df, aes(x = FPR, y = TPR, color = Label), size = 3) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "gray") +
  facet_wrap(~Model) +
  scale_color_brewer(palette = "Dark2") +
  theme_minimal() +
  labs(
    title = "ROC Curves Across Models",
    x = "False Positive Rate (1 - Specificity)",
    y = "True Positive Rate (Sensitivity)",
    color = "Model (AUC)"
  ) +
  theme(
    legend.position = "bottom",
    legend.box = "horizontal",
    legend.title = element_text(size = 8),
    legend.text = element_text(size = 8),
    legend.key.width = unit(1.2, "cm"),
    legend.spacing.x = unit(0.6, "cm"),
    axis.text = element_text(size = 8),
    axis.title = element_text(size = 8)
  ) +
  guides(color = guide_legend(nrow = 2, byrow = TRUE))

```

**Insights**

**Results Summary**

# Conclusion and Recommendations

## Conclusion {#conclusion}

## Recommendations and Next Steps
